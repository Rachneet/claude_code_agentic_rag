# Module 7: Hybrid Search & Reranking

## Complexity: ⚠️ Medium

## Context

Current retrieval (`backend/app/ingestion/retrieval.py`) is vector-only: embed query → call `match_document_chunks` RPC → return results by cosine similarity. This misses keyword-exact matches (e.g. entity names, technical terms). Module 7 adds:

1. **Hybrid search** — run vector + PostgreSQL full-text search in parallel, merge with Reciprocal Rank Fusion (RRF)
2. **Cross-encoder reranking** — rerank fused candidates via HuggingFace Inference API for higher precision

No frontend changes. No new Python dependencies (`httpx` already installed).

---

## Tasks

### Task 1: SQL migration — FTS infrastructure
**Create** `backend/supabase/migrations/007_hybrid_search.sql`

- Add `fts tsvector` column to `document_chunks`
- GIN index on `fts`
- Trigger to auto-populate `fts` on INSERT/UPDATE of `content`
- Backfill existing rows
- New RPC function `match_document_chunks_fts(query_text, match_user_id, match_count, metadata_filter)` using `websearch_to_tsquery` + `ts_rank_cd`

Trigger approach means zero ingestion code changes — tsvector is generated server-side on every chunk insert.

```sql
-- 1. Add tsvector column
ALTER TABLE public.document_chunks ADD COLUMN IF NOT EXISTS fts tsvector;

-- 2. GIN index
CREATE INDEX IF NOT EXISTS idx_document_chunks_fts ON public.document_chunks USING gin (fts);

-- 3. Trigger function
CREATE OR REPLACE FUNCTION public.document_chunks_fts_trigger()
RETURNS trigger LANGUAGE plpgsql AS $$
BEGIN
  NEW.fts := to_tsvector('english', COALESCE(NEW.content, ''));
  RETURN NEW;
END;
$$;

DROP TRIGGER IF EXISTS trg_document_chunks_fts ON public.document_chunks;
CREATE TRIGGER trg_document_chunks_fts
  BEFORE INSERT OR UPDATE OF content ON public.document_chunks
  FOR EACH ROW EXECUTE FUNCTION public.document_chunks_fts_trigger();

-- 4. Backfill
UPDATE public.document_chunks SET fts = to_tsvector('english', COALESCE(content, '')) WHERE fts IS NULL;

-- 5. FTS RPC function
CREATE OR REPLACE FUNCTION public.match_document_chunks_fts(
  query_text text, match_user_id uuid, match_count int DEFAULT 5, metadata_filter jsonb DEFAULT NULL
) RETURNS TABLE (id uuid, document_id uuid, content text, chunk_index int, token_count int, metadata jsonb, rank real)
LANGUAGE sql STABLE AS $$
  SELECT dc.id, dc.document_id, dc.content, dc.chunk_index, dc.token_count, dc.metadata,
         ts_rank_cd(dc.fts, websearch_to_tsquery('english', query_text)) AS rank
  FROM public.document_chunks dc
  WHERE dc.user_id = match_user_id
    AND dc.fts @@ websearch_to_tsquery('english', query_text)
    AND (metadata_filter IS NULL OR dc.metadata @> metadata_filter)
  ORDER BY rank DESC LIMIT match_count;
$$;
```

**Validate:** Run migration, then `SELECT id, fts IS NOT NULL FROM document_chunks LIMIT 5` — all true.

---

### Task 2: Config — reranker & hybrid settings
**Modify** `backend/app/config.py` — add after `hf_embedding_model` (line 22):

```python
# Hybrid search & reranking
reranker_enabled: bool = True
reranker_model: str = "BAAI/bge-reranker-v2-m3"
hybrid_search_enabled: bool = True
```

**Modify** `backend/.env.example` — add at end:

```
# Hybrid Search & Reranking
RERANKER_ENABLED=true
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
HYBRID_SEARCH_ENABLED=true
```

**Validate:** Backend boots without errors.

---

### Task 3: Create reranker module
**Create** `backend/app/ingestion/reranker.py`

- `rerank_chunks(query, chunks, top_k)` — calls HF Inference API `/models/{model}` with `{"query": query, "texts": [...], "truncate": True}`
- Uses raw `httpx.post` (no `InferenceClient.rerank` method exists)
- Response: `[{"index": int, "score": float}, ...]` — map scores back, sort descending
- On any error: log warning, return original order (graceful fallback)
- `@traceable(name="rerank_chunks")` for LangSmith
- Skips if `settings.reranker_enabled` is False

HF Inference endpoint: `https://router.huggingface.co/hf-inference/models/{model}`

**Validate:** Manual test with 3 chunks and a targeted query — reranked order should put the most relevant chunk first.

---

### Task 4: Rewrite retrieval for hybrid search + reranking
**Modify** `backend/app/ingestion/retrieval.py`

Refactor into:
- `_vector_search(query, user_id, threshold, count, metadata_filter)` — existing logic, calls `match_document_chunks` RPC
- `_fulltext_search(query, user_id, count, metadata_filter)` — new, calls `match_document_chunks_fts` RPC
- `_reciprocal_rank_fusion(result_lists, k=60)` — RRF: `score(d) = sum(1/(k + rank_i))`, dedup by chunk id
- `search_documents(query, user_id, ..., search_strategy="auto")` — orchestrator:
  - If hybrid: run both searches in parallel via `ThreadPoolExecutor(max_workers=2)`, fuse with RRF, rerank top candidates
  - If vector-only: existing behavior, optionally rerank
  - Fetch `count * 2` candidates from each source before fusion to give reranker enough material
- `format_retrieval_context(chunks)` — updated to prefer `rerank_score > rrf_score > similarity` for display

New `search_strategy` param: `"auto"` (uses `settings.hybrid_search_enabled`), `"hybrid"`, or `"vector"`. Default `"auto"` preserves backward compatibility — all existing callers work unchanged.

**Validate:** With `HYBRID_SEARCH_ENABLED=true`, search returns results from both vector and FTS. With `false`, falls back to vector-only.

---

### Task 5: Update chat tools — optional search_strategy param
**Modify** `backend/app/chat/tools.py`

Add `search_strategy` property to `SEARCH_DOCUMENTS_TOOL["parameters"]["properties"]`:
```python
"search_strategy": {
    "type": "string",
    "description": "Search strategy: 'auto' (default), 'vector', or 'hybrid'.",
    "enum": ["auto", "vector", "hybrid"],
},
```

In `execute_tool()`, extract and pass to `search_documents()`:
```python
search_strategy = args.get("search_strategy", "auto")
chunks = search_documents(query, user_id, metadata_filter=metadata_filter, search_strategy=search_strategy)
```

**Validate:** Tool-calling providers (Gemini/OpenRouter) can pass search_strategy. Default "auto" works for all providers.

---

### Task 6: Update PROGRESS.md

---

## Files Summary

| File | Action |
|------|--------|
| `backend/supabase/migrations/007_hybrid_search.sql` | **Create** |
| `backend/app/config.py` | Modify (3 settings) |
| `backend/.env.example` | Modify (3 env vars) |
| `backend/app/ingestion/reranker.py` | **Create** |
| `backend/app/ingestion/retrieval.py` | Modify (full rewrite) |
| `backend/app/chat/tools.py` | Modify (search_strategy param) |
| `PROGRESS.md` | Modify |

## Verification
1. Run migration 007 in Supabase — verify `fts` column populated on existing chunks
2. Upload a new document — verify new chunks get `fts` auto-populated via trigger
3. Chat with `HYBRID_SEARCH_ENABLED=true`, `RERANKER_ENABLED=true` — check LangSmith trace shows vector + FTS hits, RRF fusion, reranking
4. Set `RERANKER_ENABLED=false` — verify search still works with RRF scores only
5. Set `HYBRID_SEARCH_ENABLED=false` — verify pure vector search (pre-Module 7 behavior)
6. Test a keyword-heavy query (entity name, technical term) — hybrid should outperform vector-only

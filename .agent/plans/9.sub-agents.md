# Module 9: Sub-Agents

## Complexity: ðŸ”´ Complex

## Context

Current tool calling is single-round: LLM detects tools â†’ executes all â†’ generates one response. Sub-agents need multi-turn reasoning (call tool, see result, call another tool, repeat). Solution: each agent is a tool with its own internal ReAct loop using the provider's `chat_completion_with_tools` method iteratively.

**Three agents:**
1. **Research Agent** â€” multi-source research across docs + web, synthesizes comprehensive answers
2. **Document Q&A Agent** â€” multi-hop reasoning over uploaded documents (compare, cross-reference)
3. **Task Planner Agent** â€” decomposes requests into ordered steps, executes sequentially

No frontend changes. No new dependencies.

---

## Tasks

### Task 1: Config settings
**Modify** `backend/app/config.py` + `backend/.env.example`

```python
# Sub-agent settings
agents_research_enabled: bool = True
agents_docqa_enabled: bool = True
agents_planner_enabled: bool = True
agent_max_iterations: int = 6
agent_max_tokens: int = 4096
```

---

### Task 2: Add `format_tool_messages()` to LLM providers

The agent loop needs to append tool call + tool result messages back to the conversation for the next iteration. Each provider formats these differently.

**Modify** `backend/app/llm/base.py` â€” add method to ABC:
```python
def format_tool_messages(self, tool_calls_response: dict, tool_results: list[dict]) -> list[dict]:
```

**Modify** `backend/app/llm/huggingface.py` + `backend/app/llm/openrouter.py` â€” OpenAI-compatible format:
- Assistant message with `tool_calls` array
- Tool result messages with `role: "tool"`, `tool_call_id`

**Modify** `backend/app/llm/gemini.py` â€” extend `_convert_messages()` to handle:
- Assistant messages with `tool_calls` key â†’ `types.Part.from_function_call()`
- `role: "tool"` messages â†’ `types.Part.from_function_response()`
- Then `format_tool_messages()` uses same OpenAI-compatible output format

---

### Task 3: Create base agent with ReAct loop
**Create** `backend/app/agents/__init__.py` (empty)
**Create** `backend/app/agents/base.py`

- `BaseAgent` class with abstract `get_system_prompt()` and `get_tools()`
- `run(task, user_id)` method â€” the ReAct loop:
  1. Send messages + tools to `provider.chat_completion_with_tools()` (non-streaming)
  2. If content returned â†’ done, return it
  3. If tool_calls â†’ execute via `execute_tool_for_agent()`, format results, loop back to step 1
  4. Cap at `settings.agent_max_iterations`
  5. On cap: ask LLM for final answer without tools
- `@traceable(name="agent_run")` for LangSmith
- Temperature 0.3 (more deterministic than conversational)

---

### Task 4: Create Research Agent
**Create** `backend/app/agents/research.py`

- Tools: search_documents, web_search, fetch_url, calculate
- System prompt: break question into sub-queries, search docs first, then web, synthesize with citations

---

### Task 5: Create Document Q&A Agent
**Create** `backend/app/agents/docqa.py`

- Tools: search_documents, calculate
- System prompt: targeted searches with different queries, use metadata filters, cross-reference, cite documents

---

### Task 6: Create Task Planner Agent
**Create** `backend/app/agents/planner.py`

- Tools: all enabled tools (via `get_enabled_tools()` minus agent tools)
- `max_iterations = 10` (planners need more steps)
- System prompt: state plan first, execute steps, report per-step results, final summary

---

### Task 7: Register agents as tools + recursion guard
**Modify** `backend/app/chat/tools.py`

- Add 3 agent tool declarations (each takes a `task` string param)
- Update `get_enabled_tools()` to include agents based on config flags
- Add `execute_tool_for_agent()` â€” same as `execute_tool()` but rejects agent tool names (prevents infinite recursion)
- Extend `execute_tool()` with 3 agent branches: instantiate agent, call `agent.run(task, user_id)`

---

### Task 8: Update chat service system prompt
**Modify** `backend/app/chat/service.py`

- Add agent descriptions to `_build_tool_system_prompt()`
- Add routing guidance: simple questions â†’ direct tools, complex research â†’ research_agent, multi-hop docs â†’ docqa_agent, multi-step tasks â†’ planner_agent

---

### Task 9: Update PROGRESS.md

---

## Files Summary

| File | Action |
|------|--------|
| `backend/app/config.py` | Modify (5 settings) |
| `backend/.env.example` | Modify (5 env vars) |
| `backend/app/llm/base.py` | Modify (add format_tool_messages) |
| `backend/app/llm/huggingface.py` | Modify (implement format_tool_messages) |
| `backend/app/llm/openrouter.py` | Modify (implement format_tool_messages) |
| `backend/app/llm/gemini.py` | Modify (format_tool_messages + extend _convert_messages) |
| `backend/app/agents/__init__.py` | **Create** |
| `backend/app/agents/base.py` | **Create** (ReAct loop) |
| `backend/app/agents/research.py` | **Create** |
| `backend/app/agents/docqa.py` | **Create** |
| `backend/app/agents/planner.py` | **Create** |
| `backend/app/chat/tools.py` | Modify (3 declarations, dispatcher, recursion guard) |
| `backend/app/chat/service.py` | Modify (agent-aware prompt) |
| `PROGRESS.md` | Modify |

## Verification
1. Boot test â€” 8 tools in `get_enabled_tools()` (5 tools + 3 agents)
2. Research: "Research the latest developments in transformers" â†’ agent runs multiple iterations
3. Doc Q&A: "Compare conclusions from doc A and doc B" â†’ multi-hop document search
4. Planner: "Find Bitcoin price, calculate 0.5 BTC value, search my docs for crypto" â†’ 3-step plan
5. Simple questions bypass agents â†’ `calculate` or `search_documents` used directly
6. Recursion guard: agent can't invoke another agent
7. Max iterations cap works
8. LangSmith traces show agent chains with nested calls
